## Sort 
### Heapify
1. Runtime Complexity

### Merge Sort
1. Runtime Complexity: worse case: O(nlogn). 
2. Application: Merge sort is more efficient than quicksort for some types of lists if the data to be sorted can only be efficiently accessed sequentially.  
3. It is a divide-and-conquer algorithm. The `divide` procedure does nothing, and sorting actually happens at combine step. 
4. It is not a in-place sorting algorithm. 

### Quick Sort
1. Worse case: O(n^2); Best case: O(nlogn). 
2. It is a divide-and-conquer algorithm.   
First a pivot is picked, and then all elements less than pivot is placed in its left; and then recursively calling the quickSort() on two partitioned array.  
3. It is a in-place sorting. 



### Insertion Sort



## OOD
1. Least-Recent Used Cache
2. Least-Frequent Used Cache
3. Min Stack
4. Use Queue to implement Stack
5. Use Stack to implement Queue

## Binary Search 

## Back-tracking
1. Examples using back-tracking to sovle. [Geeks4Geeks](http://www.geeksforgeeks.org/category/algorithm/backtracking/)

## Dynamic Programming

## Depth-First Search

## Topological Sort 
1. [Geeks4Geeks](http://www.geeksforgeeks.org/topological-sorting/). The algorithm is similar to DFS.  
2. Typical problems that use topological sort: library dependency. 

## Breath-First Search
### Two-way BFS 


## List
### LinkedList
1. [Reverse a Linked List in groups of given size](http://www.geeksforgeeks.org/reverse-a-list-in-groups-of-given-size/)  
```
Example:
Inputs:  1->2->3->4->5->6->7->8->NULL and k = 3 
Output:  3->2->1->6->5->4->8->7->NULL. 

Inputs:   1->2->3->4->5->6->7->8->NULL and k = 5
Output:  5->4->3->2->1->8->7->6->NULL. 
```

## Trie

## Union Find

## Graph






